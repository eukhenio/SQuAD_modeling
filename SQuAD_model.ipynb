{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SQuAD_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1yRzWdXgl0LMG4wX8qJriGE1FU8mT_bKk","authorship_tag":"ABX9TyNz2g6JcgxatDeJ8eSANfdk"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xvYmvWsFh_pW","colab_type":"code","colab":{}},"source":["import re\n","import numpy as np\n","from keras.preprocessing.sequence import pad_sequences\n","import json\n","\n","from keras import layers\n","from keras.layers import recurrent\n","from keras.layers.embeddings import Embedding\n","from keras.models import Model\n","\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnPjeq_UCfiY","colab_type":"code","colab":{}},"source":["def tokenize(sent):\n","  return [x.strip() for x in re.split(r'(\\W+)', sent) if x.strip()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"04eRKr61iNrv","colab_type":"code","outputId":"2d920fbd-f57e-4370-b6b5-2e3a6ead1750","executionInfo":{"status":"ok","timestamp":1591420228935,"user_tz":-180,"elapsed":6484,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["with open('drive/My Drive/final_project/train-v2.0.json', 'r') as f:\n","  content = json.loads(f.read())\n","type(content)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"WbaD0NJViWn4","colab_type":"code","outputId":"988fdfca-385e-434b-b730-152e876a161e","executionInfo":{"status":"ok","timestamp":1591420360511,"user_tz":-180,"elapsed":805,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(content.keys())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["dict_keys(['version', 'data'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e1Q-1EUKicKS","colab_type":"code","outputId":"fa7e0126-7015-4fb8-db90-8caa290f397e","executionInfo":{"status":"ok","timestamp":1591420363310,"user_tz":-180,"elapsed":823,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data = content['data']\n","data[0].keys()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['title', 'paragraphs'])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"sNt55UuKiiX9","colab_type":"code","outputId":"bf522a2d-b10c-4c95-b72c-7d061b6acee4","executionInfo":{"status":"ok","timestamp":1591420365508,"user_tz":-180,"elapsed":789,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":751}},"source":["data[320]['paragraphs'][0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': 'The modern English word green comes from the Middle English and Anglo-Saxon word grene, from the same Germanic root as the words \"grass\" and \"grow\". It is the color of living grass and leaves and as a result is the color most associated with springtime, growth and nature. By far the largest contributor to green in nature is chlorophyll, the chemical by which plants photosynthesize and convert sunlight into chemical energy. Many creatures have adapted to their green environments by taking on a green hue themselves as camouflage. Several minerals have a green color, including the emerald, which is colored green by its chromium content.',\n"," 'qas': [{'answers': [{'answer_start': 326, 'text': 'chlorophyll'}],\n","   'id': '5729604faf94a219006aa341',\n","   'is_impossible': False,\n","   'question': 'What, in nature, is most likely to make things green?'},\n","  {'answers': [{'answer_start': 522, 'text': 'camouflage'}],\n","   'id': '5729604faf94a219006aa342',\n","   'is_impossible': False,\n","   'question': 'For what do some animals use the color green?'},\n","  {'answers': [{'answer_start': 624, 'text': 'chromium'}],\n","   'id': '5729604faf94a219006aa343',\n","   'is_impossible': False,\n","   'question': 'What chemical causes emeralds to be green?'},\n","  {'answers': [{'answer_start': 81, 'text': 'grene'}],\n","   'id': '5729604faf94a219006aa344',\n","   'is_impossible': False,\n","   'question': 'From which Middle English and Anglo-Saxon word is green derived?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a08',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 81, 'text': 'grene'}],\n","   'question': 'What is the Germanic root word meaning grass?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a09',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 326, 'text': 'chlorophyll'}],\n","   'question': 'What chemical for converting sunlight is found in emeralds?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a0a',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 81, 'text': 'grene'}],\n","   'question': 'What word came from the English word \"green\"?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a0b',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 410, 'text': 'chemical energy'}],\n","   'question': 'What do plants convert chlorophyll into?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a0c',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 368, 'text': 'photosynthesize'}],\n","   'question': 'What process does chromium allow plants to do?'}]}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"5qDF-uNZdjj8","colab_type":"code","colab":{}},"source":["def parse_data(data):\n","  vocab_set = set()\n","  vocab = {}\n","  triplex_list = []\n","  context_list = []\n","  question_list = []\n","  answer_list = []\n","\n","  # Context and questions extracting\n","  for topic in data:\n","    for part in topic['paragraphs']:\n","      blocks = part['qas']\n","      for block in blocks:\n","        context = part['context']\n","        vocab_set |= set(tokenize(context))\n","        context_list.append(context)\n","        vocab_set |= set(tokenize(block['question']))\n","        question_list.append(block['question'])\n","\n","  # Making dictionary with shape {'token': number}, where numbers are in range 1..\n","  i = 1\n","  for token in vocab_set:\n","    vocab[token] = i\n","    i += 1\n","  \n","  # Context vectorization and finding of context_maxlen\n","  context_vectors = []\n","  context_maxlen = 0\n","  for context in context_list:\n","    vectorized_context = []\n","    tokens = tokenize(context)\n","    for token in tokens:\n","      vectorized_context.append(vocab[token])\n","    context_vectors.append(vectorized_context)\n","    if len(tokens) > context_maxlen:\n","      context_maxlen = len(tokens)\n","  context_vectors = pad_sequences(context_vectors, maxlen=context_maxlen, padding='post')\n","\n","  # Answers extracting and vectorization\n","  for topic in data:\n","    for part in topic['paragraphs']:\n","      blocks = part['qas']\n","      for block in blocks:\n","        answer = np.zeros(context_maxlen + 1)\n","        if len(block['answers']) == 1:\n","          answer_start = block['answers'][0]['answer_start']\n","          text = block['answers'][0]['text']\n","          answer[answer_start:answer_start + len(text)] = 1\n","        answer_list.append(answer)\n","    answer_vectors = pad_sequences(answer_list, maxlen=context_maxlen, padding='post')\n","  \n","  # Question vectorization and question_maxlen finding \n","  question_vectors = []\n","  question_maxlen = 0\n","  for question in question_list:\n","    vectorized_question = []\n","    tokens = tokenize(question)\n","    for token in tokens:\n","      vectorized_question.append(vocab[token])\n","    question_vectors.append(vectorized_question)\n","    if len(tokens) > question_maxlen:\n","      question_maxlen = len(tokens)\n","  question_vectors = pad_sequences(question_vectors, maxlen=question_maxlen, padding='post')\n","\n","\n","  return context_vectors, question_vectors, answer_vectors, vocab, context_maxlen, question_maxlen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7g1W5GRitqg","colab_type":"code","colab":{}},"source":["context_vectors, question_vectors, answer_vectors, vocab, context_maxlen, question_maxlen = parse_data(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5M5um3tYbCq-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"751a85dc-c07b-49ab-ef29-40d297195a7a","executionInfo":{"status":"ok","timestamp":1591457811753,"user_tz":-180,"elapsed":951,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}}},"source":["print('context ', type(context_vectors))\n","print('question ', type(question_vectors))\n","print('answer ', type(answer_vectors))\n","print('context ', context_vectors.shape)\n","print('question ', question_vectors.shape)\n","print('answer ', answer_vectors.shape)\n","print('context_maxlen= ', context_maxlen)\n","print('question_maxlen= ', question_maxlen)\n","print('Length of vocabulary= ', len(vocab))\n"],"execution_count":179,"outputs":[{"output_type":"stream","text":["context  <class 'numpy.ndarray'>\n","question  <class 'numpy.ndarray'>\n","answer  <class 'numpy.ndarray'>\n","context  (130319, 844)\n","question  (130319, 60)\n","answer  (130319, 844)\n","context_maxlen=  844\n","question_maxlen=  60\n","Length of vocabulary=  99372\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2TCbXj-_49vc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"30383f6b-f94c-4439-b657-ba8e67d3eccc","executionInfo":{"status":"ok","timestamp":1591458278906,"user_tz":-180,"elapsed":741,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}}},"source":["RNN = recurrent.LSTM\n","EMBED_HIDDEN_SIZE = 50\n","CONTEXT_HIDDEN_SIZE = 100\n","QUESTION_HIDDEN_SIZE = 100\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","vocab_size = len(vocab) + 1\n","print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n","                                                           EMBED_HIDDEN_SIZE,\n","                                                           CONTEXT_HIDDEN_SIZE,\n","                                                           QUESTION_HIDDEN_SIZE))"],"execution_count":182,"outputs":[{"output_type":"stream","text":["RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 50, 100, 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZJzXKnCb5eXQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"e4bffc36-dead-4b09-93db-1e8aaa5a1af2","executionInfo":{"status":"ok","timestamp":1591460800238,"user_tz":-180,"elapsed":6012,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}}},"source":["print('Build model...')\n","\n","context = layers.Input(shape=(context_maxlen,), dtype='int32')\n","encoded_context = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(context)\n","encoded_context = RNN(CONTEXT_HIDDEN_SIZE)(encoded_context)\n","\n","question = layers.Input(shape=(question_maxlen,), dtype='int32')\n","encoded_question = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\n","encoded_question = RNN(QUESTION_HIDDEN_SIZE)(encoded_question)\n","\n","merged = layers.concatenate([encoded_context, encoded_question])\n","preds = layers.Dense(vocab_size, activation='softmax')(merged)\n","\n","model = Model([context, question], preds)\n","model.compile(optimizer='rmsprop',\n","              loss=tf.nn.sigmoid_cross_entropy_with_logits,\n","              metrics=['mse'])\n","\n","\n","model.summary()"],"execution_count":189,"outputs":[{"output_type":"stream","text":["Build model...\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            (None, 844)          0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            (None, 60)           0                                            \n","__________________________________________________________________________________________________\n","embedding_5 (Embedding)         (None, 844, 50)      4968650     input_5[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_6 (Embedding)         (None, 60, 50)       4968650     input_6[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_5 (LSTM)                   (None, 100)          60400       embedding_5[0][0]                \n","__________________________________________________________________________________________________\n","lstm_6 (LSTM)                   (None, 100)          60400       embedding_6[0][0]                \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 200)          0           lstm_5[0][0]                     \n","                                                                 lstm_6[0][0]                     \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 99373)        19973973    concatenate_3[0][0]              \n","==================================================================================================\n","Total params: 30,032,073\n","Trainable params: 30,032,073\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cAqoCe5lVcWO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"outputId":"0999e5e7-31b8-47cf-8f0b-dc31ffefb146","executionInfo":{"status":"error","timestamp":1591460933541,"user_tz":-180,"elapsed":12633,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}}},"source":["print('Training')\n","model.fit([context_vectors, question_vectors], answer_vectors,\n","          batch_size=BATCH_SIZE,\n","          epochs=EPOCHS,\n","          validation_split=0.05)\n"],"execution_count":190,"outputs":[{"output_type":"stream","text":["Training\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 123803 samples, validate on 6516 samples\n","Epoch 1/20\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-190-03d511c3bf74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_split=0.05)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [32,99373] vs. [32,844]\n\t [[node gradients/loss_2/dense_3_loss/sigmoid_cross_entropy_with_logits_v2/logistic_loss/mul_grad/BroadcastGradientArgs (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_4228]\n\nFunction call stack:\nkeras_scratch_graph\n"]}]},{"cell_type":"code","metadata":{"id":"bJdeW7ZCdePE","colab_type":"code","colab":{}},"source":["print('Evaluation')\n","loss, mse = model.evaluate([tx, txq], ty,\n","                           batch_size=BATCH_SIZE)\n","print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, mse))"],"execution_count":0,"outputs":[]}]}