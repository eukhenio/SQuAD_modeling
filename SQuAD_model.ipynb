{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SQuAD_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1yRzWdXgl0LMG4wX8qJriGE1FU8mT_bKk","authorship_tag":"ABX9TyOtRTxEQ/xjT2aoPfGZyhDJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FnPjeq_UCfiY","colab_type":"code","outputId":"262696a6-6657-4aac-ee7f-e7f190314cab","executionInfo":{"status":"ok","timestamp":1591680592199,"user_tz":-180,"elapsed":4199,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pickle\n","\n","import re\n","import numpy as np\n","from keras.preprocessing.sequence import pad_sequences\n","import json\n","\n","from keras import layers\n","from keras.layers import recurrent\n","from keras.layers.embeddings import Embedding\n","from keras.models import Model\n","\n","import tensorflow as tf\n","\n","from sklearn.metrics import hamming_loss, precision_score,\\\n","                             recall_score, accuracy_score\n","from sklearn.metrics.pairwise import cosine_distances\n","from scipy.spatial.distance import cosine"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dvtg4-0sIep-","colab_type":"code","colab":{}},"source":["def tokenize(sent):\n","  return [x.strip() for x in re.split(r'(\\W+)', sent) if x.strip()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"04eRKr61iNrv","colab_type":"code","outputId":"b72497f4-3a54-4c55-f431-773d1247cbf1","executionInfo":{"status":"ok","timestamp":1591521848464,"user_tz":-180,"elapsed":9267,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["with open('drive/My Drive/final_project/train-v2.0.json', 'r') as f:\n","  content = json.loads(f.read())\n","type(content)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"WbaD0NJViWn4","colab_type":"code","outputId":"988fdfca-385e-434b-b730-152e876a161e","executionInfo":{"status":"ok","timestamp":1591420360511,"user_tz":-180,"elapsed":805,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(content.keys())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["dict_keys(['version', 'data'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e1Q-1EUKicKS","colab_type":"code","outputId":"96f4fff1-f9c2-4396-d1c1-21ea477c0621","executionInfo":{"status":"ok","timestamp":1591521853507,"user_tz":-180,"elapsed":1083,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data = content['data']\n","data[0].keys()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['title', 'paragraphs'])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"sNt55UuKiiX9","colab_type":"code","outputId":"bf522a2d-b10c-4c95-b72c-7d061b6acee4","executionInfo":{"status":"ok","timestamp":1591420365508,"user_tz":-180,"elapsed":789,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":751}},"source":["data[320]['paragraphs'][0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': 'The modern English word green comes from the Middle English and Anglo-Saxon word grene, from the same Germanic root as the words \"grass\" and \"grow\". It is the color of living grass and leaves and as a result is the color most associated with springtime, growth and nature. By far the largest contributor to green in nature is chlorophyll, the chemical by which plants photosynthesize and convert sunlight into chemical energy. Many creatures have adapted to their green environments by taking on a green hue themselves as camouflage. Several minerals have a green color, including the emerald, which is colored green by its chromium content.',\n"," 'qas': [{'answers': [{'answer_start': 326, 'text': 'chlorophyll'}],\n","   'id': '5729604faf94a219006aa341',\n","   'is_impossible': False,\n","   'question': 'What, in nature, is most likely to make things green?'},\n","  {'answers': [{'answer_start': 522, 'text': 'camouflage'}],\n","   'id': '5729604faf94a219006aa342',\n","   'is_impossible': False,\n","   'question': 'For what do some animals use the color green?'},\n","  {'answers': [{'answer_start': 624, 'text': 'chromium'}],\n","   'id': '5729604faf94a219006aa343',\n","   'is_impossible': False,\n","   'question': 'What chemical causes emeralds to be green?'},\n","  {'answers': [{'answer_start': 81, 'text': 'grene'}],\n","   'id': '5729604faf94a219006aa344',\n","   'is_impossible': False,\n","   'question': 'From which Middle English and Anglo-Saxon word is green derived?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a08',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 81, 'text': 'grene'}],\n","   'question': 'What is the Germanic root word meaning grass?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a09',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 326, 'text': 'chlorophyll'}],\n","   'question': 'What chemical for converting sunlight is found in emeralds?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a0a',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 81, 'text': 'grene'}],\n","   'question': 'What word came from the English word \"green\"?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a0b',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 410, 'text': 'chemical energy'}],\n","   'question': 'What do plants convert chlorophyll into?'},\n","  {'answers': [],\n","   'id': '5a74990f42eae6001a389a0c',\n","   'is_impossible': True,\n","   'plausible_answers': [{'answer_start': 368, 'text': 'photosynthesize'}],\n","   'question': 'What process does chromium allow plants to do?'}]}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"5qDF-uNZdjj8","colab_type":"code","colab":{}},"source":["def parse_data(data):\n","  vocab_set = set()\n","  vocab = {}\n","  triplex_list = []\n","  context_list = []\n","  question_list = []\n","  answer_list = []\n","\n","  # Context and questions extracting\n","  for topic in data:\n","    for part in topic['paragraphs']:\n","      blocks = part['qas']\n","      for block in blocks:\n","        context = part['context']\n","        vocab_set |= set(tokenize(context))\n","        context_list.append(context)\n","        vocab_set |= set(tokenize(block['question']))\n","        question_list.append(block['question'])\n","\n","  # Making dictionary with shape {'token': number}, where numbers are in range 1..\n","  i = 1\n","  for token in vocab_set:\n","    vocab[token] = i\n","    i += 1\n","  \n","  # Context vectorization and finding of context_maxlen\n","  context_vectors = []\n","  context_maxlen = 0\n","  for context in context_list:\n","    vectorized_context = []\n","    tokens = tokenize(context)\n","    for token in tokens:\n","      vectorized_context.append(vocab[token])\n","    context_vectors.append(vectorized_context)\n","    if len(tokens) > context_maxlen:\n","      context_maxlen = len(tokens)\n","  context_vectors = pad_sequences(context_vectors, maxlen=context_maxlen, padding='post')\n","\n","  # Answers extracting and vectorization\n","  for topic in data:\n","    for part in topic['paragraphs']:\n","      blocks = part['qas']\n","      for block in blocks:\n","        answer = np.zeros(context_maxlen + 1)\n","        if len(block['answers']) == 1:\n","          answer_start = block['answers'][0]['answer_start']\n","          text = block['answers'][0]['text']\n","          answer[answer_start:answer_start + len(text)] = 1\n","        answer_list.append(answer)\n","    answer_vectors = pad_sequences(answer_list, maxlen=context_maxlen, padding='post')\n","  \n","  # Question vectorization and question_maxlen finding \n","  question_vectors = []\n","  question_maxlen = 0\n","  for question in question_list:\n","    vectorized_question = []\n","    tokens = tokenize(question)\n","    for token in tokens:\n","      vectorized_question.append(vocab[token])\n","    question_vectors.append(vectorized_question)\n","    if len(tokens) > question_maxlen:\n","      question_maxlen = len(tokens)\n","  question_vectors = pad_sequences(question_vectors, maxlen=question_maxlen, padding='post')\n","\n","\n","  return context_vectors, question_vectors, answer_vectors, vocab, context_maxlen, question_maxlen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e7g1W5GRitqg","colab_type":"code","colab":{}},"source":["context_vectors, question_vectors, answer_vectors, vocab, context_maxlen, question_maxlen = parse_data(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"chDAA01GYvPm","colab_type":"code","colab":{}},"source":["with open('drive/My Drive/final_project/context_vectors.pickle', 'wb') as f:\n","  pickle.dump(context_vectors, f)\n","with open('drive/My Drive/final_project/question_vectors.pickle', 'wb') as f:\n","  pickle.dump(question_vectors, f)\n","with open('drive/My Drive/final_project/answer_vectors.pickle', 'wb') as f:\n","  pickle.dump(answer_vectors, f)\n","other = {'vocab': vocab, 'context_maxlen': context_maxlen, 'question_maxlen': question_maxlen}\n","with open('drive/My Drive/final_project/other.pickle', 'wb') as f:\n","  pickle.dump(other, f)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqsPDuJPdT4I","colab_type":"code","colab":{}},"source":["with open('drive/My Drive/final_project/context_vectors.pickle', 'rb') as f:\n","  context_vectors = pickle.load(f)\n","with open('drive/My Drive/final_project/question_vectors.pickle', 'rb') as f:\n","  question_vectors = pickle.load(f)\n","with open('drive/My Drive/final_project/answer_vectors.pickle', 'rb') as f:\n","  answer_vectors = pickle.load(f)\n","with open('drive/My Drive/final_project/other.pickle', 'rb') as f:\n","  other = pickle.load(f)\n","vocab = other['vocab']\n","context_maxlen = other['context_maxlen']\n","question_maxlen = other['question_maxlen']\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5M5um3tYbCq-","colab_type":"code","outputId":"751a85dc-c07b-49ab-ef29-40d297195a7a","executionInfo":{"status":"ok","timestamp":1591457811753,"user_tz":-180,"elapsed":951,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["print('context ', type(context_vectors))\n","print('question ', type(question_vectors))\n","print('answer ', type(answer_vectors))\n","print('context ', context_vectors.shape)\n","print('question ', question_vectors.shape)\n","print('answer ', answer_vectors.shape)\n","print('context_maxlen= ', context_maxlen)\n","print('question_maxlen= ', question_maxlen)\n","print('Length of vocabulary= ', len(vocab))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["context  <class 'numpy.ndarray'>\n","question  <class 'numpy.ndarray'>\n","answer  <class 'numpy.ndarray'>\n","context  (130319, 844)\n","question  (130319, 60)\n","answer  (130319, 844)\n","context_maxlen=  844\n","question_maxlen=  60\n","Length of vocabulary=  99372\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dw2ht1cvrn1G","colab_type":"code","outputId":"5f9548ce-d83f-4ff5-bccb-e7eda597159b","executionInfo":{"status":"ok","timestamp":1591685459867,"user_tz":-180,"elapsed":1620,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["from sklearn.model_selection import train_test_split\n","context_train, context_test, question_train, question_test,\\\n","  answer_train, answer_test = train_test_split(context_vectors,\n","  question_vectors, answer_vectors, test_size=0.2, random_state=42)\n","\n","print('context_train', type(context_train), context_train.shape)\n","print('context_test', type(context_test), context_test.shape)\n","print('question_train', type(question_train), question_train.shape)\n","print('question_test', type(question_test), question_test.shape)\n","print('answer_train', type(answer_train), answer_train.shape)\n","print('answer_test', type(answer_test), answer_test.shape)\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["context_train <class 'numpy.ndarray'> (104255, 844)\n","context_test <class 'numpy.ndarray'> (26064, 844)\n","question_train <class 'numpy.ndarray'> (104255, 60)\n","question_test <class 'numpy.ndarray'> (26064, 60)\n","answer_train <class 'numpy.ndarray'> (104255, 844)\n","answer_test <class 'numpy.ndarray'> (26064, 844)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2TCbXj-_49vc","colab_type":"code","outputId":"fc8dcfd4-901c-44f2-8466-47b1f8eac799","executionInfo":{"status":"ok","timestamp":1591680635175,"user_tz":-180,"elapsed":1150,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["RNN = recurrent.LSTM\n","EMBED_HIDDEN_SIZE = 10\n","CONTEXT_HIDDEN_SIZE = 20\n","QUESTION_HIDDEN_SIZE = 20\n","BATCH_SIZE = 256\n","EPOCHS = 20\n","vocab_size = len(vocab) + 1\n","print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n","                                                           EMBED_HIDDEN_SIZE,\n","                                                           CONTEXT_HIDDEN_SIZE,\n","                                                           QUESTION_HIDDEN_SIZE))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 10, 20, 20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nM_-3b1lJn62","colab_type":"code","outputId":"66742b9e-901e-4291-ccc6-7c7eca32c378","executionInfo":{"status":"ok","timestamp":1591683381569,"user_tz":-180,"elapsed":1032,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["a = [1, 2, 3, 4, 5, 6, 7]\n","t = tf.constant([a])\n","\n","def to_numpy(tensor_1D):\n","  buff = []\n","  for i in tensor_1D:\n","    buff.append(i)\n","  return np.asarray(buff)\n","\n","type(t)\n","a = t.numpy()\n","a"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2, 3, 4, 5, 6, 7]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"ZJzXKnCb5eXQ","colab_type":"code","outputId":"9ded6b50-719c-46c5-c3d4-d9fb195ecfee","executionInfo":{"status":"error","timestamp":1591685618870,"user_tz":-180,"elapsed":1097,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}},"colab":{"base_uri":"https://localhost:8080/","height":392}},"source":["print('Build model...')\n","\n","context = layers.Input(shape=(context_maxlen,), dtype='int32')\n","encoded_context = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(context)\n","encoded_context = RNN(CONTEXT_HIDDEN_SIZE)(encoded_context)\n","\n","question = layers.Input(shape=(question_maxlen,), dtype='int32')\n","encoded_question = layers.Embedding(vocab_size, EMBED_HIDDEN_SIZE)(question)\n","encoded_question = RNN(QUESTION_HIDDEN_SIZE)(encoded_question)\n","\n","merged = layers.concatenate([encoded_context, encoded_question])\n","preds = layers.Dense(context_maxlen, activation='sigmoid')(merged)\n","\n","model = Model([context, question], preds)\n","model.compile(optimizer='rmsprop',\n","              loss=tf.nn.sigmoid_cross_entropy_with_logits,\n","              metrics=['accuracy',\\\n","                       np.array([cosine(answer, preds) for answer in answer_train])])\n","\n","model.summary()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Build model...\n"],"name":"stdout"},{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-69d97b076fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m               metrics=['accuracy',\\\n\u001b[0;32m---> 18\u001b[0;31m                        np.array([cosine(answer, preds) for answer in answer_train])])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-69d97b076fe5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m               metrics=['accuracy',\\\n\u001b[0;32m---> 18\u001b[0;31m                        np.array([cosine(answer, preds) for answer in answer_train])])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;31m#   or 'reflective correlation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \"\"\"\n\u001b[1;32m    708\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;31m# XXX Is order='c' really necessary?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;31m# Ensure values such as u=1 and u=[1] still return 1-D arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    747\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001b[0;32m--> 749\u001b[0;31m                               \" array.\".format(self.name))\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (dense_13/Sigmoid:0) to a numpy array."]}]},{"cell_type":"code","metadata":{"id":"hlmwEsBCln-h","colab_type":"code","colab":{}},"source":["[cosine(answers, preds) for answers in answer_train])]\n","np.array([ds.cosine(answer, preds[0]) for answer in answer_train])])\n","cosine_distances(answer_train, preds)\n","tf.convert_to_tensor(arg, dtype=tf.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNmMobrfp8oG","colab_type":"code","colab":{}},"source":["sess = tf.compat.v1.Session()\n",">>> with sess.as_default():\n",">>>    print(type(tf.constant([1,2,3]).eval()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHYlqe3Kqz5w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"7e9f7567-16b3-4399-b18b-085155f8a642","executionInfo":{"status":"ok","timestamp":1591683120764,"user_tz":-180,"elapsed":1032,"user":{"displayName":"Евгений Мотылев","photoUrl":"","userId":"00574812871737722118"}}},"source":["a = tf.constant([[1, 2], [3, 4]])                 \n","print(type(a))\n","a = a.numpy()\n","type(a)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["<class 'tensorflow.python.framework.ops.EagerTensor'>\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"cAqoCe5lVcWO","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","\n","callback = ModelCheckpoint(filepath='/content/drive/My Drive/final_project/weights_file_1',\n","              monitor='val_loss',\n","              mode='auto',\n","              save_best_only=True)\n","\n","print('Training')\n","history = model.fit([context_train, question_train], answer_train,\n","          batch_size=BATCH_SIZE,\n","          epochs=EPOCHS,\n","          validation_split=0.05,\n","          callbacks=[callback])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6Ek-w2KUXHG","colab_type":"code","colab":{}},"source":["accuracy=history.history['accuracy']\n","val_accuracy=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","print('accuracy= ', mse)\n","print('val_accuracy= ', val_mse)\n","print('loss= ', loss)\n","print('val_loss= ', val_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJdeW7ZCdePE","colab_type":"code","colab":{}},"source":["print('Evaluation')\n","loss, accuracy = model.evaluate([context_test, question_test], answer_test,\n","                           batch_size=BATCH_SIZE)\n","print('Test loss / test mse = {:.4f} / {:.4f}'.format(loss, accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bJytOWOkmll","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import model_from_json\n","\n","json_file = '/content/drive/My Drive/final_project/model.json'\n","model_json_1 = model.to_json()\n","\n","with open(json_file, 'w') as f:\n","  f.write(model_json_1)\n"],"execution_count":0,"outputs":[]}]}